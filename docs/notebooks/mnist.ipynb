{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01f18ce1f5dafdd64deafeec68568c5f",
   "metadata": {},
   "source": [
    "# MNIST: Hand-written Digits Classification\n",
    "\n",
    "The MNIST dataset is considered to be the \"hello world\" example of machine\n",
    "learning. In that same spirit, we'll be making the \"hello world\" UnionML app\n",
    "using this dataset and a simple linear classifier with\n",
    "[sklearn](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "Because modeling this dataset is such a well-worn path, we'll see just how easy\n",
    "it is to create a single-script UnionML app.\n",
    "\n",
    "```{note}\n",
    "This tutorial is adapted from this [sklearn guide](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de213eaa1559df0cd04daffc2d950969",
   "metadata": {
    "tags": [
     "colab-deps",
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install pandas sklearn unionml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac3b7d644e4163a293166bbd9ac2aa1",
   "metadata": {},
   "source": [
    "First let's import our dependencies and create the UnionML `Dataset` and `Model`\n",
    "objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bec3a73925ce8ee2a77a7392af7dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from unionml import Dataset, Model\n",
    "\n",
    "\n",
    "dataset = Dataset(name=\"mnist_dataset\", test_size=0.2, shuffle=True, targets=[\"class\"])\n",
    "model = Model(name=\"mnist_classifier\", init=LogisticRegression, dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0813628d0a5d230f85f3393fa3e31255",
   "metadata": {},
   "source": [
    "For convenience, we cache the dataset so that MNIST loading is faster upon subsequent calls\n",
    "to the `fetch_openml` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e40c53aa64199773e4da1de57edb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(Path.home() / \"tmp\")\n",
    "fetch_openml_cached = memory.cache(fetch_openml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f209adb3aa2b833d3b7c5649ca063a5",
   "metadata": {},
   "source": [
    "Next, we define our core UnionML app functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0df598009f32549c8fe68b4495853d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataset.reader\n",
    "def reader() -> pd.DataFrame:\n",
    "    dataset = fetch_openml_cached(\n",
    "        \"mnist_784\",\n",
    "        version=1,\n",
    "        cache=True,\n",
    "        as_frame=True,\n",
    "    )\n",
    "    return dataset.frame\n",
    "\n",
    "\n",
    "@model.init\n",
    "def init(hyperparameters: dict) -> Pipeline:\n",
    "    estimator = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", LogisticRegression()),\n",
    "        ]\n",
    "    )\n",
    "    return estimator.set_params(**hyperparameters)\n",
    "\n",
    "\n",
    "@model.trainer\n",
    "def trainer(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    ") -> Pipeline:\n",
    "    return estimator.fit(features, target.squeeze())\n",
    "\n",
    "\n",
    "@model.predictor\n",
    "def predictor(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    ") -> List[float]:\n",
    "    return [float(x) for x in estimator.predict(features)]\n",
    "\n",
    "\n",
    "@model.evaluator\n",
    "def evaluator(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    ") -> float:\n",
    "    return float(accuracy_score(target.squeeze(), estimator.predict(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d764052663485fb16891df8be22c3d11",
   "metadata": {},
   "source": [
    "### Training a Model Locally\n",
    "\n",
    "Then we can train our model locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bbfec787edde4ac3f824c555a348dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator, metrics = model.train(\n",
    "    hyperparameters={\n",
    "        \"classifier__penalty\": \"l2\",\n",
    "        \"classifier__C\": 0.1,\n",
    "        \"classifier__max_iter\": 10000,\n",
    "    }\n",
    ")\n",
    "features = reader().sample(5, random_state=42).drop([\"class\"], axis=\"columns\")\n",
    "print(estimator, metrics, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a83bd92c60eb0ee172bdc8cba2333e",
   "metadata": {},
   "source": [
    "### Serving on a Gradio Widget\n",
    "\n",
    "Finally, let's create a `gradio` widget by simply using the `model.predict` method into\n",
    "the `gradio.Interface` object.\n",
    "\n",
    "Before we do this, however, we want to define a `feature_loader` function to handle the raw input\n",
    "coming from the `gradio` widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acdd83fda12e1448e6a8c245cc664a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@dataset.feature_loader\n",
    "def feature_loader(data: np.ndarray) -> pd.DataFrame:\n",
    "    return (\n",
    "        pd.DataFrame(data.ravel())\n",
    "        .transpose()\n",
    "        .rename(columns=lambda x: f\"pixel{x + 1}\")\n",
    "        .astype(float)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c430bbb96bdaee1eb1a75ff02341e",
   "metadata": {},
   "source": [
    "We also need to take care to handle the `None` case when we press\n",
    "the `clear` button on the widget using a `lambda` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1a7d3119a61de3f7d448776ddcea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(\n",
    "    fn=lambda img: img if img is None else model.predict(img)[0],\n",
    "    inputs=\"sketchpad\",\n",
    "    outputs=\"label\",\n",
    "    live=True,\n",
    "    allow_flagging=\"never\",\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
