{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82cd1ee547e881ed1fa8f670aa16f8ce",
   "metadata": {},
   "source": [
    "# MNIST: Digits Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9ffd7ac510842f5ed6bba778575685",
   "metadata": {
    "tags": [
     "add-colab-badge"
    ]
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/unionai-oss/unionml/blob/main/docs/notebooks/mnist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee342f8a1b049e0ee880c0293c6e665",
   "metadata": {},
   "source": [
    "The MNIST dataset is considered to be the \"hello world\" example of machine\n",
    "learning. In that same spirit, we'll be making the \"hello world\" UnionML app\n",
    "using this dataset and a simple linear classifier with\n",
    "[sklearn](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "With this dataset, we'll see just how easy it is to create a single-script UnionML app.\n",
    "\n",
    "```{note}\n",
    "This tutorial is adapted from this [sklearn guide](https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1cc7d5a6fc56f3863473b0dcf38c40",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gradio pandas sklearn unionml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d27c34587d6abdd7105e34c4d47ae04",
   "metadata": {},
   "source": [
    "First let's import our dependencies and create the UnionML `Dataset` and `Model`\n",
    "objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad91a61bed4fb5fb14386ac7ccdd7706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Union\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from unionml import Dataset, Model\n",
    "\n",
    "\n",
    "dataset = Dataset(name=\"mnist_dataset\", test_size=0.2, shuffle=True, targets=[\"class\"])\n",
    "model = Model(name=\"mnist_classifier\", init=LogisticRegression, dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8cfd5c5d698e9a8ad778b08a1cf7ee",
   "metadata": {},
   "source": [
    "For convenience, we cache the dataset so that MNIST loading is faster upon subsequent calls\n",
    "to the `fetch_openml` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb063d7a33d2d3f4f37b0a895768f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(Path.home() / \"tmp\")\n",
    "fetch_openml_cached = memory.cache(fetch_openml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd1822459d417b352454bd9872453a",
   "metadata": {},
   "source": [
    "Next, we define our core UnionML app functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d5d5fbde37766348d9ce2bafbad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataset.reader(cache=True, cache_version=\"1\")\n",
    "def reader() -> pd.DataFrame:\n",
    "    dataset = fetch_openml_cached(\n",
    "        \"mnist_784\",\n",
    "        version=1,\n",
    "        cache=True,\n",
    "        as_frame=True,\n",
    "    )\n",
    "    return dataset.frame\n",
    "\n",
    "\n",
    "@model.init\n",
    "def init(hyperparameters: dict) -> Pipeline:\n",
    "    estimator = Pipeline(\n",
    "        [\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"classifier\", LogisticRegression()),\n",
    "        ]\n",
    "    )\n",
    "    return estimator.set_params(**hyperparameters)\n",
    "\n",
    "\n",
    "@model.trainer(cache=True, cache_version=\"1\")\n",
    "def trainer(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    ") -> Pipeline:\n",
    "    return estimator.fit(features, target.squeeze())\n",
    "\n",
    "\n",
    "@model.predictor\n",
    "def predictor(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    ") -> List[float]:\n",
    "    return [float(x) for x in estimator.predict(features)]\n",
    "\n",
    "\n",
    "@model.evaluator\n",
    "def evaluator(\n",
    "    estimator: Pipeline,\n",
    "    features: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    ") -> float:\n",
    "    return float(accuracy_score(target.squeeze(), estimator.predict(features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dffa1592f19ba37568327de9c82ac36",
   "metadata": {},
   "source": [
    "## Training a Model Locally\n",
    "\n",
    "Then we can train our model locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc561226e6d44ad01cdb17a0129bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator, metrics = model.train(\n",
    "    hyperparameters={\n",
    "        \"classifier__penalty\": \"l2\",\n",
    "        \"classifier__C\": 0.1,\n",
    "        \"classifier__max_iter\": 1000,\n",
    "    }\n",
    ")\n",
    "features = reader().sample(5, random_state=42).drop([\"class\"], axis=\"columns\")\n",
    "print(estimator, metrics, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88cb741ba2c00a6e653b322ec0f7a93",
   "metadata": {},
   "source": [
    "## Serving on a Gradio Widget\n",
    "\n",
    "Finally, let's create a `gradio` widget by simply using the `model.predict` method into\n",
    "the `gradio.Interface` object.\n",
    "\n",
    "Before we do this, however, we want to define a `feature_loader` function to handle the raw input\n",
    "coming from the `gradio` widget:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a1bfdf4691fe451fdc74db717f0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "@dataset.feature_loader\n",
    "def feature_loader(data: np.ndarray) -> pd.DataFrame:\n",
    "    return (\n",
    "        pd.DataFrame(data.ravel())\n",
    "        .transpose()\n",
    "        .rename(columns=lambda x: f\"pixel{x + 1}\")\n",
    "        .astype(float)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8444d768eaaadb54bda8962a8f7d42d9",
   "metadata": {},
   "source": [
    "We also need to take care to handle the `None` case when we press\n",
    "the `clear` button on the widget using a `lambda` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a48de174544d0d83dffb1bceaca24b",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.Interface(\n",
    "    fn=lambda img: img if img is None else model.predict(img)[0],\n",
    "    inputs=\"sketchpad\",\n",
    "    outputs=\"label\",\n",
    "    live=True,\n",
    "    allow_flagging=\"never\",\n",
    ").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
